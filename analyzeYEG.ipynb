{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build NA covid data for all airport comparisons\n",
    "# Build total + new NA cases\n",
    "NaData = pd.read_csv(\"Archieved-Data/casesNA.csv\", compression = 'gzip')\n",
    "NaData[\"Date\"] = pd.to_datetime(NaData[\"Date\"])\n",
    "NaSums = NaData.groupby(NaData['Date']).sum().reset_index()\n",
    "naCases = NaSums[['Date','Confirmed']]\n",
    "temp = naCases.shift(1)\n",
    "naCases['New'] = naCases['Confirmed'] - temp['Confirmed']\n",
    "naCases.loc[0,\"New\"] = 0\n",
    "new_cases_smooth = lowess(naCases['New'], naCases[\"Date\"], frac =0.05)\n",
    "confirm_smooth = lowess(naCases['Confirmed'], naCases[\"Date\"], frac =0.05)\n",
    "naCases['New_smooth'] = new_cases_smooth[:,1]\n",
    "naCases['Confirm_smooth'] = confirm_smooth[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeg = pd.read_csv('yeg4analyze_both.csv',index_col =0, parse_dates = [1])\n",
    "yegCases = pd.read_csv('Covid-Data/yeg-modified.csv', index_col =0, parse_dates = [5])\n",
    "\n",
    "yeg[\"Date\"] = pd.to_datetime(yeg[\"Date\"])\n",
    "yegCases[\"Date\"] = pd.to_datetime(yegCases[\"Date\"])\n",
    "\n",
    "yegCases.loc[0, \"Difference\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "plt.plot(yeg[\"Date\"], yeg['PercentOfBaseline'], 'b-', label = 'Percentage Baseline')\n",
    "plt.plot(yegCases[\"Date\"], yegCases['Difference'], 'r-', label = 'Difference in Cases', alpha = 0.4)\n",
    "#plt.plot(yegCases[\"Date\"], yegCases['Confirmed'], 'm-', label = 'Difference in Cases', alpha = 0.4)\n",
    "plt.xlabel(\"Mid-March to Mid October\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small curve in initial phase (Mid-Apr), flattened down shortly after \n",
    "# Steep increases after the Summer - look for causes \n",
    "# Called in military to assist with rising cases; lockdown\n",
    "# % Baseline didn't change dramatically (decrease in business trips and international travel)\n",
    "# Small dips\n",
    "\n",
    "new_cases_smooth = lowess(yegCases['Difference'], yegCases[\"timestamp\"], frac =0.05)\n",
    "#to reduce weekly cycle effect 7/214 = 0.327\n",
    "baseline_smooth = lowess(yeg['PercentOfBaseline'], yeg[\"Date\"], frac =0.04) \n",
    "yegCases['Diff_smooth'] = new_cases_smooth[:,1]\n",
    "yegCases['Diff_smooth'] = new_cases_smooth[:,1]\n",
    "yeg['Baseline_smooth'] = baseline_smooth[:,1]\n",
    "\n",
    "# Ensure both yeg and yegCases start and end on the same dates\n",
    "if (yeg.count().loc['Date'] != yegCases.count().loc['Date']):\n",
    "    joined = yegCases[[\"Date\",\"Difference\",\"Confirmed\",\"Diff_smooth\"]].join(yeg[[\"Date\",\"PercentOfBaseline\",\"Baseline_smooth\"]].set_index('Date'), on='Date')\n",
    "    joined = joined.dropna()\n",
    "    X = joined[\"Diff_smooth\"]\n",
    "    y = joined[\"Baseline_smooth\"]\n",
    "else:\n",
    "    X = yegCases[\"Diff_smooth\"]\n",
    "    y = yeg[\"Baseline_smooth\"]\n",
    "\n",
    "plt.figure(figsize = (20,5))\n",
    "plt.plot(yeg[\"Date\"], yeg['PercentOfBaseline'], 'b.', label = 'Percentage Baseline', alpha=0.4)\n",
    "plt.plot(yeg[\"Date\"], yeg['Baseline_smooth'],'b-',label = 'Smoothed % Baseline')\n",
    "plt.plot(yegCases[\"Date\"], yegCases[\"Diff_smooth\"], 'r-', label = 'Smoothed New Cases', alpha = 0.5)\n",
    "plt.plot(yegCases[\"Date\"], yegCases['Difference'], 'r.', label = 'New Cases', alpha = 0.4)\n",
    "plt.xlabel(\"Mid-March to Mid October\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find statistical correlation between the two values- Baseline, and New Cases, using the filtered data from above\n",
    "plt.plot(X,y, 'b.')\n",
    "plt.xlabel('New Cases per day')\n",
    "plt.ylabel('Baseline % of Airport Traffic')\n",
    "regression = stats.linregress(X, y)\n",
    "\n",
    "print(regression.rvalue)\n",
    "\n",
    "# 311 = max(X)\n",
    "linearX = np.linspace(0, max(X)) \n",
    "plt.plot(linearX, regression.slope*linearX + regression.intercept,'r-')\n",
    "\n",
    "# r-value: Slight but negligible correlation \n",
    "# imbalanced data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Number of Confirmed Patients\n",
    "confirm_smooth = lowess(joined['Confirmed'], joined[\"Date\"], frac =0.04)\n",
    "# to reduce weekly cycle effect 7/214 = 0.327\n",
    "confirmX = confirm_smooth[:,1]\n",
    "plt.plot(confirmX,y, 'b.')\n",
    "plt.xlabel('Total Confirmed Cases')\n",
    "plt.ylabel('Baseline % of Airport Traffic')\n",
    "\n",
    "reg = stats.linregress(confirmX, y)\n",
    "\n",
    "print(reg.rvalue)\n",
    "\n",
    "linearX = np.linspace(0, max(confirmX)) \n",
    "plt.plot(linearX, reg.slope*linearX + reg.intercept,'r-')\n",
    "\n",
    "# r-value: slight positive correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([confirmX], axis =1)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y)\n",
    "plt.plot(confirmX,y, 'b.')\n",
    "plt.xlabel('Total Confirmed Cases')\n",
    "plt.ylabel('Baseline % of Airport Traffic')\n",
    "\n",
    "poly_regress = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    #PolynomialFeatures(degree=2, include_bias = True),\n",
    "    #LinearRegression(fit_intercept = False)\n",
    "    KNeighborsRegressor(3)\n",
    ")\n",
    "poly_regress.fit(X_train, y_train)\n",
    "\n",
    "linearX = np.stack([np.linspace(0,max(confirmX))],axis=1)\n",
    "plt.plot(linearX, poly_regress.predict(linearX), 'r-')\n",
    "\n",
    "# Hmmm... not too bad. Could be smoothed out more\n",
    "print(poly_regress.score(X_train,y_train))\n",
    "print(poly_regress.score(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing statistical correlation in --> Wave 1\n",
    "first_wave = joined[joined['Date']<'2020-06-01']\n",
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "\"\"\"plt.plot(first_wave[\"Date\"], first_wave['PercentOfBaseline'], 'b.', label = 'Percentage Baseline', alpha=0.7)\n",
    "plt.plot(first_wave[\"Date\"], first_wave['Baseline_smooth'],'b-',label = 'Smoothed % Baseline')\n",
    "plt.plot(first_wave[\"Date\"], first_wave[\"Diff_smooth\"], 'r-', label = 'Smoothed New Cases', alpha = 0.5)\n",
    "plt.plot(first_wave[\"Date\"], first_wave['Difference'], 'r.', label = 'New Cases', alpha = 0.7)\n",
    "plt.xlabel(\"Mid-March to Mid-May: First Wave\")\n",
    "plt.legend()\n",
    "plt.show() #two things over time\"\"\"\n",
    "\n",
    "plt.plot(first_wave[\"Confirmed\"],first_wave[\"Baseline_smooth\"], 'b.', label = 'Presented Data')\n",
    "plt.xlabel(\"Total Confirmed Cases in AB\")\n",
    "plt.ylabel(\"Baseline % of airport traffic\")\n",
    "\n",
    "regression = stats.linregress(first_wave[\"Confirmed\"], first_wave[\"Baseline_smooth\"])\n",
    "print(regression.rvalue)\n",
    "# weak correlation\n",
    "linearX = np.linspace(400, max(first_wave[\"Confirmed\"]))\n",
    "plt.plot(linearX, regression.slope*linearX + regression.intercept,'r--', label = 'Entire Curve')\n",
    "\n",
    "# Analyze the tail of the first wave: The last 30 days \n",
    "# i.e. when it tapered down in May\n",
    "reg2 = stats.linregress(first_wave[\"Confirmed\"].tail(30), first_wave[\"Baseline_smooth\"].tail(30))\n",
    "print(reg2.rvalue)\n",
    "# No correlation\n",
    "lin2 = np.linspace(400, max(first_wave[\"Confirmed\"]))\n",
    "plt.plot(lin2, reg2.slope*lin2+ reg2.intercept,'g--', label = 'End of Curve')\n",
    "\n",
    "# Analyze the first month the curve: the month where it kept climbing up\n",
    "reg3 = stats.linregress(first_wave[\"Confirmed\"].head(30), first_wave[\"Baseline_smooth\"].head(30))\n",
    "print(reg3.rvalue)\n",
    "# Moderate correlation\n",
    "lin3 = np.linspace(400, max(first_wave[\"Confirmed\"]))\n",
    "plt.plot(lin3, reg3.slope*lin3+ reg3.intercept,'m--', label = 'Beginning of Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make sure both yeg and naCases start and end on the same dates\n",
    "if (yeg.count().loc['Date'] != naCases.count().loc['Date']):\n",
    "    joined = naCases[[\"Date\",\"Confirmed\",\"New\"]].join(yeg[[\"Date\",\"PercentOfBaseline\",\"Baseline_smooth\"]].set_index('Date'), on='Date')\n",
    "    joined = joined.dropna()\n",
    "\n",
    "# How to interpret?\n",
    "plt.scatter(joined['Confirmed'],joined['Baseline_smooth'],c=joined['Date'],cmap='winter' )\n",
    "# Should be just NA?\n",
    "plt.xlabel(\"NA Confirmed Cases\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.ylabel(\"Baseline Smoothed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB regressor does the best out of all of them bc diff factors are weighed differently\n",
    "# Also not that much data, so neural network doesn't really work\n",
    "gbmodel = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    GradientBoostingRegressor(n_estimators=50, max_depth=5)\n",
    "    )\n",
    "gbmodel.fit(X_train, y_train)\n",
    "\n",
    "linearX = np.stack([np.linspace(0,11500)],axis=1)\n",
    "plt.plot(linearX, poly_regress.predict(linearX), 'r-') \n",
    "\"\"\"NOTE:WHY POLY_REGRESS HERE?\"\"\"\n",
    "#print(knmodel.score(X_train,y_train), knmodel.score(X_valid,y_valid))\n",
    "#print(rfmodel.score(X_train,y_train), rfmodel.score(X_valid,y_valid))\n",
    "#print(nnmodel.score(X_train,y_train), nnmodel.score(X_valid,y_valid))\n",
    "print(gbmodel.score(X_train,y_train), gbmodel.score(X_valid,y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
